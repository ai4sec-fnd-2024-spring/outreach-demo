{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bb00f9-4be4-44a9-a850-4d476b507ae9",
   "metadata": {},
   "source": [
    "# Assignment 1b: Adversarial Minesweeper\n",
    "In the previous assignment, you were introduced to heuristic-based graph search using the game *Minesweeper*. In that assignment, you were also introduced to several techniques for creating and training agents to play Minesweeper. In this assignment, you will explore ways to understand and hinder the performance of such agents. As usual, execute the following cell to begin the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245698d2-3b40-48db-86be-e8486c3d9ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/RobertTLange/evosax.git@main\n",
    "\n",
    "import random\n",
    "import statistics\n",
    "import evosax\n",
    "from evosax import ParameterReshaper, FitnessShaper\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from flax import linen as nn\n",
    "import numpy as np\n",
    "from minesweeper import MinesweeperGame, render_map\n",
    "import json\n",
    "import utils1b\n",
    "\n",
    "\n",
    "example_instances = {\n",
    "    'beginner' : [\n",
    "        [0,0,0,0,0,1,0,0,0],\n",
    "        [0,0,0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0,0,1],\n",
    "        [0,0,0,1,0,1,0,0,0],\n",
    "        [0,1,0,0,0,0,0,0,1],\n",
    "        [0,0,1,0,0,0,0,1,1],\n",
    "        [0,0,0,0,0,0,0,1,0],\n",
    "        [0,0,0,0,0,0,0,0,0]\n",
    "    ],\n",
    "    \n",
    "    'intermediate' : [\n",
    "        [0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "        [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "        [1,1,0,1,0,0,0,1,0,0,1,0,0,0,0,1],\n",
    "        [0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1],\n",
    "        [1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "        [0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,1],\n",
    "        [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "        [0,0,0,1,0,1,0,0,0,0,0,0,0,1,0,0],\n",
    "        [0,0,0,0,1,1,0,0,0,1,0,0,1,0,0,0],\n",
    "        [0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0],\n",
    "        [0,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0],\n",
    "        [1,0,0,0,0,1,1,0,0,0,0,0,0,1,0,0],\n",
    "        [1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0],\n",
    "        [0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "    ],\n",
    "    \n",
    "    'expert' : [\n",
    "        [1,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1],\n",
    "        [0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0,0,0],\n",
    "        [0,0,0,0,1,1,0,0,1,0,0,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1],\n",
    "        [0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "        [0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0],\n",
    "        [0,1,0,0,0,1,1,0,0,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,0,1,0,0,1,0,1,0,1,1,0],\n",
    "        [0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "        [0,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1,0,0,0],\n",
    "        [0,1,1,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1,1,0,1,0,1,0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0],\n",
    "        [0,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0],\n",
    "        [0,0,0,0,0,1,0,0,0,1,1,0,1,1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0],\n",
    "        [0,0,0,1,0,1,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,1,1,0,0,0],\n",
    "        [0,0,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "print('The first cell has been executed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95ec62-27e2-4128-add5-d51fd0becb35",
   "metadata": {},
   "source": [
    "In this assignment, we'll provide you with a pretrained agent that performs meaningfully well on the minesweeper instances used in the previous assignment. Execute the following cell to load the parameters of this agent and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbbd4fe-a4ee-41e7-93bc-e6ac102f567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./reference_agent.json') as file:\n",
    "    encoded_params = json.load(file)\n",
    "reference_agent = utils1b.agent_decoder(encoded_params)\n",
    "network = utils1b.MLP(num_hidden_units=48, num_hidden_layers=2, num_output_units=1)\n",
    "network_apply = jax.jit(network.apply)\n",
    "for name, map_instance in example_instances.items():\n",
    "    score, solution, num_actions = utils1b.neural_network_agent(map_instance, network_apply, reference_agent, enforce_reachability=True)\n",
    "    print(f'{name} score: {score}')\n",
    "    print(f'number of actions on {name} instance until game over: {num_actions}')\n",
    "    print(f'{name} solution:')\n",
    "    render_map(solution, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9803b-81c3-47f8-9252-73353c0272a3",
   "metadata": {},
   "source": [
    "Recall that in Assignment 1a, we decided to use neuroevolution to train an agent using a deterministic heuristic in an effort to achieve performances comparable to the best scores achieved by a stochastic agent that uniform-randomly selected actions. There is an important assumption behind the decision to use a deterministic heuristic that we overlooked though. Namely, for a deterministic agent of this nature to perform optimally on every instance of Minesweeper, the agent would need to be able to discern the best action to make without ambiguity. Simply put, this is impossible in our formulation of Minesweeper.\n",
    "\n",
    "Consider a Minesweeper instance where the initial space revealed at the start of the game contains a `1`. This value indicates that one of the eight surrounding cells contains a mine. At this point, the agent must select one of the surrounding eight cells for the next move, but there simply isn't enough information to *guarantee* the selection of a cell without a mine. Furthermore, the deterministic behavior of our agent guarantees that the same action would be selected every time. In other words, regardless of where other mines may be placed on the map, when our agent encounters a starting cell with a value of `1`, it will always select the same cell. The agent may select a different cell if the value were `2`, for example, but, because the agent is deterministic, the agent effectively has a hard-coded action it will always make for each non-zero value of the starting cell. The behavior we've just discussed is inherent to any *deterministic agent* we might try on our version of Minesweeper and not, for example, a consequence of using a neural network, specifically.\n",
    "\n",
    "Despite the parameters of the neural network being unintelligible, and perhaps being unfamiliar with neural networks on the whole, you can now begin to characterize and (to a limited extent) reason about the agent's behavior. We'll leverage this insight to begin creating Minesweeper problem instances that exploit this understanding and impact the agent's performance.\n",
    "\n",
    "## Minesweeper Problem Instances\n",
    "As was demonstrated earlier in this notebook and in Assignment 1a, Minesweeper problem instances are defined as 2D binary lists where cells with a value of `1` contain a mine and cells with a value of `0` do not contain a mine. While there are almost certainly Minesweeper instances which will cause crashes and unintended behaviors in the Minesweeper environment, our goal is not to find them. In general, adhere to the following rules when completing exercises in this assignment:\n",
    "1. the minimum board size is 5x5, as this is the size of the box used to generate observations;\n",
    "2. the starting location must not contain a mine (by default, this is the middle of the board);\n",
    "3. rows and columns in the binary list must be of a consistent size; and\n",
    "4. the binary values in the 2D list are expressed as integers (as opposed to Bools), for conciseness.\n",
    "\n",
    "## Minesweeper Scoring\n",
    "In order to understand agent performance on Minesweeper, we should understand how score is calculated on Minesweeper. This was briefly mentioned in Assignment 1a, but (for the sake of clarity) score is calculated using the following equation:  \n",
    "$score = revealed\\_cells/mineless\\_cells$.\n",
    "\n",
    "Recall that our version of Minesweeper is modified from the original to make it a graph traversal problem. We can only select cells immediately diagonal or adjacent to already revealed cells. As a consequence, of the location selected at the start of the game and the graph of cells connected to that cell, it is possible to define Minesweeper problem instances with inaccessible locations (as reaching these cells would require traversing cells containing mines). As such, when `enforce_reachability=True`, $mineless\\_cells$ is calculated using only cells without mines that are reachable from the start location. When `enforce_reachability=False`, we calculate $mineless\\_cells$ using all cells without mines, regardless of the ability to reach these locations from the start location.\n",
    "\n",
    "## Exercise 0\n",
    "Implement a Minesweeper problem instance, with a single mine, in which the agent fails in their first action. We define failure in this case as making an action to select a cell containing a mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45614790-2039-4ccf-9b23-5f88e63002f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this problem instance to define mine placement\n",
    "exercise_0 = [\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]\n",
    "]\n",
    "\n",
    "starting_mine, mine_count = utils1b.map_check(exercise_0)\n",
    "if starting_mine:\n",
    "    print('Error: mine place in default starting location')\n",
    "elif mine_count == 0:\n",
    "    print('Please define mine placement in exercise_0')\n",
    "elif mine_count > 1:\n",
    "    print('Please place only a single mine for this exercise')\n",
    "else:\n",
    "    score, solution, num_actions = utils1b.neural_network_agent(exercise_0, network_apply, reference_agent, enforce_reachability=True)\n",
    "    print(f'Exercise 0 score: {score}')\n",
    "    print(f'Number of actions: {num_actions}')\n",
    "    print(f'Exercise 0 solution:')\n",
    "    render_map(solution, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40297b3e-2711-4d65-8df6-cf138f140dfa",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Implement a Minesweeper problem instance, with a single mine, in which the agent achieves a complete solution in their first action. In other words, the first action of the agent should reveal all cells without a mine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff2e5a-1ed1-4dbe-8ff6-df290e9d7afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Modify this problem instance to define mine placement\n",
    "exercise_1 = [\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]\n",
    "]\n",
    "\n",
    "starting_mine, mine_count = utils1b.map_check(exercise_1)\n",
    "if starting_mine:\n",
    "    print('Error: mine place in default starting location')\n",
    "elif mine_count == 0:\n",
    "    print('Please define mine placement in exercise_1')\n",
    "elif mine_count > 1:\n",
    "    print('Please place only a single mine for this exercise')\n",
    "else:\n",
    "    score, solution, num_actions = utils1b.neural_network_agent(exercise_1, network_apply, reference_agent, enforce_reachability=True)\n",
    "    print(f'Exercise 1 score: {score}')\n",
    "    print(f'Number of actions: {num_actions}')\n",
    "    print(f'Exercise 1 solution:')\n",
    "    render_map(solution, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0dd6e-aee6-4247-b35e-73a9db9e1795",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Implement a Minesweeper problem instance in which the agent selects a different cell for their starting move. Hint: you can use as many mines as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f3c64-41e9-4245-8c83-a0f8f4d45a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify this problem instance to define mine placement\n",
    "exercise_2 = [\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0],\n",
    "    [0,0,0,0,0]\n",
    "]\n",
    "\n",
    "starting_mine, mine_count = utils1b.map_check(exercise_2)\n",
    "if starting_mine:\n",
    "    print('Error: mine place in default starting location')\n",
    "elif mine_count == 0:\n",
    "    print('Please define mine placement in exercise_2')\n",
    "else:\n",
    "    score, solution, num_actions = utils1b.neural_network_agent(exercise_2, network_apply, reference_agent, enforce_reachability=True)\n",
    "    print(f'Exercise 2 score: {score}')\n",
    "    print(f'Number of actions: {num_actions}')\n",
    "    print(f'Exercise 2 solution:')\n",
    "    render_map(solution, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261519ed-420d-4c9a-bafb-cfbe35b66431",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Implement a Minesweeper problem instance in which the agent achieves a score less than 0.01. You are welcome to use a board of whatever size and number of mines you deem appropriate, but be sure to assign your problem instance to the `exercise_3` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864df3ad-b783-4a10-9a3c-e23fbc103db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your problem instance here\n",
    "exercise_3 = None\n",
    "\n",
    "starting_mine, mine_count = utils1b.map_check(exercise_3)\n",
    "if starting_mine:\n",
    "    print('Error: mine place in default starting location')\n",
    "elif mine_count == 0:\n",
    "    print('Please define mine placement in exercise_3')\n",
    "else:\n",
    "    score, solution, num_actions = utils1b.neural_network_agent(exercise_3, network_apply, reference_agent, enforce_reachability=True)\n",
    "    print(f'Exercise 3 score: {score}')\n",
    "    print(f'Number of actions: {num_actions}')\n",
    "    print(f'Exercise 3 solution:')\n",
    "    render_map(solution, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e84612f-758b-4708-96ad-2551869563fb",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Implement a Minesweeper problem instance in which the agent achieves a score of 0.50 $\\pm$ 0.01. To simplify this exercise, we'll calculate game score with `enforce_reachability=False`, so that you can accomplish this task by simply making spaces inaccessible to the normal traversal of the agent. You are welcome to use a board of whatever size and number of mines you deem appropriate, but be sure to assign your problem instance to the `exercise_4` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49481d2-ad83-451e-a6f4-203a8397676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your problem instance here\n",
    "exercise_4 = None\n",
    "\n",
    "starting_mine, mine_count = utils1b.map_check(exercise_4)\n",
    "if starting_mine:\n",
    "    print('Error: mine place in default starting location')\n",
    "elif mine_count == 0:\n",
    "    print('Please define mine placement in exercise_4')\n",
    "else:\n",
    "    score, solution, num_actions = utils1b.neural_network_agent(exercise_4, network_apply, reference_agent, enforce_reachability=False)\n",
    "    print(f'Exercise 4 score: {score}')\n",
    "    print(f'Number of actions: {num_actions}')\n",
    "    print(f'Exercise 4 solution:')\n",
    "    render_map(solution, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169fd19-fdcb-4854-8a1f-d5036ce3f8e3",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Implement a Minesweeper problem instance in which the agent achieves a score of 0.50 $\\pm$ 0.01. To simplify this exercise, but this time we'll calculate game score with `enforce_reachability=True`. You must guarantee, then, that it is possible to reach the ~50% of non-mine cells the agent fails to select. You are welcome to use a board of whatever size and number of mines you deem appropriate, but be sure to assign your problem instance to the `exercise_5` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb51af5-02a3-4571-aef8-8283aec49252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your problem instance here\n",
    "exercise_5 = None\n",
    "\n",
    "starting_mine, mine_count = utils1b.map_check(exercise_5)\n",
    "if starting_mine:\n",
    "    print('Error: mine place in default starting location')\n",
    "elif mine_count == 0:\n",
    "    print('Please define mine placement in exercise_5')\n",
    "else:\n",
    "    score, solution, num_actions = utils1b.neural_network_agent(exercise_5, network_apply, reference_agent, enforce_reachability=True)\n",
    "    print(f'Exercise 5 score: {score}')\n",
    "    print(f'Number of actions: {num_actions}')\n",
    "    print(f'Exercise 5 solution:')\n",
    "    render_map(solution, compact=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09235640-0dc8-4d28-bdcd-a27f816400d2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
